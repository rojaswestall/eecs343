**EECS 343**

**Thursday April 19, 2019**

# Lecture 6: Memory Management Optimizations

### From last time: Virtual Memory

Page tables translate virtual page numbers to physical page numbers

There are page table entries inside page tables (PTEs)

- high bits translate from virutal page number to physical page number
- low bits tell you whether readable/writable, user accessable, kernal accessable and more

Register %CR3 value gets changed during a context switch so the OS uses a different mapping after the context switch

VM is hanlded by OS and CPU together:

- OS: sets up page tables and handle excpetions (like trying to access a memory address that isn't accesible or doesn't have a valid page)
- CPU: automatically translates every memory access in the program from virtual addresses to physical addresses by checking the page tables



## Paging Costs

#### 1. Latency

Every memory access now required an **additional read** to get the physical page number from the page table

RAM access is slow (~50ns), so this is very bad

#### 2. Space

Each process has their own page table mapping the entire address range

On a 32 bit system linear page tables would consume 4MB of mem *per process*

- assuming 4kb pages and 32 bit addresses we require one million PTEs and each PTE is 4kb



## Translation Lookaside Buffer (TLB)

Cache for recenetly used page table entries (to make access to them faster)

TLB is the solution for paging latency problems

- Uses small fraction of current page table that is stored on-chip, in fast memeory
- "Fully associative"

Caches are common in computer systems lol thanks Steve

- cache is a record of recent transactions that allows you to skip repeated requests
- web browser caches all you HTTP GET requests so that you don't have to reload repeated images, like logos, menus and other ish



## Why does a TLB help

Programs don't access random addresses, instead they're likely to need the same translations in the future

**Temporal Locality** - programs resuse the *exact* same memory addresses

**Spatial Locality** - programs typically access memory *near* recently used memory. Example:

- looping through an array (adjacent addresses)
- functions local variables and paramenters are on the same stack frame
- code has to be read from memory, and these are contiguous until a branch/jump happens

Tend to have *spatial locality* in memory access



## Cache Dynamics

A cache **hit** is when data is found in the cache. This is fast and hopefully most common

A cache **miss** is when the data is not found in the cache

- have to go to memory to find the page table translation
- low because we have to access page table in RAM
- When we're done with this, we store the data in the cache for next time, SO we have to choose an existing entry to *evict*

CPU Caches (like the TLB) make performance unpredictable because:

- it's usually invisible to the OS (excpet for software managed TLBs)
- Cache status depends on prior activity, perhaps by other processes



## Computers have a hierarchy of Storage

Disk is about *ten billion* times larger than registers, but has about *ten million* times larger delay (latency)

Goal is to work as much as possible in the top level

Large, rarely-needed data is stored at the bottom level

"memory" is not just RAM, but everything below the registers

The reason they get slower is because they are bigger, and because they are bigger, things get farther away so you have to go a further distance to access your data. The same tech more or less is used in all the different forms of memory, it's just that the distance is larger

![image-20190418125743384](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418125743384.png)

## Software-controlled Paging

Intel x86 CPUs use **hardware-managed TLB**

- CPU automatically wlaks the page table and controls the TLB

RISC CPUs (a lot of mobile) use a **software-managed TLB**

- These CPUs know nothing about page tables, just use the TLB
- If a translation is not present in the TLB, CPU causes an expcetion
- OS interrput handler consults its page tables to find the address translation
- OS evicts an entry from the TLB and addes the new translation to the TLB using special instructions
- Interrupt return instruction resumes by **repeating** the intstruction that failed since the TLB has been changed
- Flush the TLB before a context switch

This can simplify the CPU hardware and gives more control to the OS



## Reducing Space Overhead of Paging

Recall that we need 10^6 PTEs for 32-bit address space and 4kb pages

We can reduce the page table size by make pages larger

- 4MB "superpages" on the x86 lead to just 1000 PTEs (4kb overhead) per process
- Also leads to more TLB hits, because each page translations serves more data
- However, superpages are *not* a full solution
- Allocating huge pages for everything will lead to wasted space

We want to keep fine-grained page allocation, but lose some of the overhead

#### Linear (one-level) page table with 4mb (big) pages

Basically they waste space as stated before

**Two-level** page table can start small and **adapt** its size as needed



## Linear Page Table Addressing Clarification

How are 18 bits from PDE + 22bit offest (40 bits) used to find a 32-bit address?

Add 14 zeros to end of 18-bit PDE value to find the 32-bit starting address of the 4mb page (page must be aligned to a 16kb frame)

22 bit offest finds the location with that 4mb page



## Linear Page table has fixed space overhead

THe page table space overhead is actually OK for large process

- 4MB page table is just 0.1% of a process using the full 4GB of memory

However, the 4MB over head is terrible for small processes

- most of the page table will be empty:
- (PTEs will have "present" bit = 0)

![image-20190418130941019](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418130941019.png)



## Multi-level page table mechanics

- Virtual address is broken into 3 or more parts
- Highest bits index into the highest-level page table
- A pagefault can occur if an entry is missing at any level
- OS can initialize a process with just a highest-level table and just a few lower-level tables
- More tables are added as a process demands more memory



## 2-level page table addressing clarification





## Multi-level paging example

![image-20190418131430481](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418131430481.png)



## Improper Virtual Memory Access causes an Exception

Project 2.2 requires a new interrupt handler in trap.c

```c
void
trap(struct trapframe *tf)
{
  if(tf->trapno == T_SYSCALL){
    if(myproc()->killed){
      exit();
    }
    myproc()->tf = tf;
    syscall();
    if(myproc()->killed){
      exit();
    }
    return;
  }
  
  switch(tf->trapno){
    case T_IRQ0 + IRQ_TIMER:
      //handler code
    case SOME_THING :
    	// bunch of cases for different handlers
      // more cases
      // more cases
    default:
      if(myproc() == 0 || (tf->cs$3) ==0){
        //in kernel, it must be our mistake.
        cprintf("unexpected trap %d from cpu %d eip %x (cr2=0x%x)\n", tf->trapno, cpuid(), tf->eip, rcr2());
        panic("trap");
      }
      // In user space, assume process misbehaved.
      cprintf("pid %d %s: trap %d err %d on cpu %d "
              "eip 0x%x addr 0x%x--kill proc\n",
              myproc()->pid, myproc()->name, tf->trapno, tf->err, cpuid(), tf->eip, rcr2());
      myproc()->killed = 1;
  }
}
```

If there was no handler for the interrupt, the OS will either panic or it will kill the process. Default case

Allow both processes to write to that memory, but at first they can't. Need new interrupt handler for page faults essentially



## 64-bit address space requires > 3 levels

64bit address space allows $1.8 \times 10^{19} = 18 \text{ billion gigabytes}$ of memory

SO, 64-bit addresss spaces are very, very sparse

Requires 3 or 4 paging levels to keep page tables small

![image-20190418132441776](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418132441776.png)

![image-20190418132424533](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418132424533.png)

![image-20190418132454027](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418132454027.png)

## To see VM info on Linux:

- `cat` / `proc` / `meminfo`
- `vmstat`
- `top`
  - (resident)



## `top`

- gives machine level statistics
- RES column is "resident memory" - amount of physical memory being consumed
- "q" to quit
- For each process it shows how much virtual memory is being "used" by that process
- You can see that clever implementation of the OS allows for users to think they have like 10x more memory than is actually being used
- SHR is the shared memory that is being used for the process
- Virtual means program has made system calls to trigger memory
- This is on murphy or some machine like it that's why there's so many processes going on

![image-20190418133135362](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418133135362.png)



## Copy-on-write with Fork

- *`Fork` + `exec`* is the only way to create a child process in unix
- This is what we're doing on part 2 of project 2 OUR PROJECT HAS NEVER BEEN DONE BEFORE YAY
- Fork clones the entire process, including all of virutal memory
  - this can be slow and inefficient, especially if the memory will just be overwritten by a call to `exec`
- *Copy on write* is a performance optimization:
  - Don't copy the parent's pages, **share** them
    - Make the child process' page table point to the paren;s physical pages
    - Mark all the pages as "read only" in the PTEs (temporarily)
  - If parent or child writes to a shared page, a page fault excpetion will occur
  - OS handles the page fault by:
    - Copying parent's page to the child and marking both copies as writeable
    - when the faulting process is resumed, it retries the memory write

Essentially, don't copy until you absolutely KNOW that you need it. If it's just going to be overwritten anyway, why not just copy if you need it



## Demand Zeroing

another lazy optimization

- If a process asks for more memory with `sbrk` or `mmap` the OS can allocate is **lazily**
  - in other words, don't allocate the full block immediately
  - lazy allocation minimizes latency of fulfilling the reuest
  - and it prevents OS from allocatin memory that will not be used
- OS must also write zeros to newly assigned physical frames
  - So that they can't access memory in that same location that was used by the previous program
  - program does not necessarily expect the new memory to contain zeros
  - just for security so other process' data is not leaked 
- OS can keep one read-only physical page filled with zeros and just five a reference to this at first
  - After the first page fault (due to writing a read-only page), then allocate a real page



## Virtual Memory in Practice

On linux `pmap` command shows a process' VM mapping

We see:

- OS tracks while file code is loaded from, so it can be lazily loaded
- THe main process binary and libraries are **lazy loaded**, not fully in memory
- Libraries have read-only sections that can be shared with other processes

`cat` / `proc` / `<pid>` / `smaps` shows even more detail



**Steve freaking likes emacs**

![image-20190418134250468](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418134250468.png)



## Recap

**Latency Cost**: 

**Space Cost**: we have to store page tables, linear page tables are the biggest time, we can get smaller page tables by making pages bigger so we have multiople levels and only fill in lower levels wheen they are needed. We save space with fine-grained something or other. Also making page tables thmeselves is shorter

![image-20190418134813398](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190418134813398.png)


**EECS 343**

**Tuesday April 23, 2019**

# Lecture 7: Swapping

Last Lecture: VM and Paging Optimizations



## Motivation for Swapping

- Paging allows many processes to share the same physical memory
- When RAM is fully consumed, OS can react by:
  - Give up and kill the memory-hog process(es)
  - Swapping can free up some physical memory by temporarily moving some pages to disk
    - Disk is large but very slow!
    - Hopefully some of the memory used by processes is infrequently used



## Computer Storage Hierarchy

Disk is about 100 times larger than RAM but has about 10,000 times higher latency/delay if magnetic or 1000 times higher latency if SSD

Should always try to work as much as you can in the higher levels



## Swapped pages are stored on disk

On linux, swap space is a special optional disk partition:

- allocated when you install the OS
- Only used for swapping, never regular files
- Formatting is optimized for staoring page-szed chunks of data

Windows:

- Swap space can grow and shrink on demand, shares spaces with main filesystem
- More flexible but slower than linux

SSDs are better than magnetic disks for swap space, because of much lower latency (relatively little space is needed for swapping)



Swapping is a last resort because it's slow so you don't want to do it too much. XV6 doesn't have swap so it can run into memory allocation problems



## Swapping example

![image-20190423124707731](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423124707731.png)

CPU doesn't have direct access to pages on disk. So not only is it slower, but the program can't actually use the data that's on disk



## Swapping Mechanics

![image-20190423124834687](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423124834687.png)

Similar to copy on write. 



## *Page Faults* occur when PTE is marked "not present"

![image-20190423125046350](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423125046350.png)

When it checks the high bits, it uses certain conventions to store data, so it checks to make sure this data is the convention it was expecting



## Swapping in

![image-20190423125325716](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423125325716.png)

To make a free space is called **eviction**.



## Magnetic Disks

They are slow because they are mechanical



## Throughput vs Latency

![image-20190423125639654](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423125639654.png)

Throughput is bytes/second at peak/most

Latency is high for disk because it's far away from the CPU so there has to be an electrical signal. More importantly, a mechanical task needs to take place before it can read (like disk turning and arm moving out).



## Postal Analogy

![image-20190423125946151](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423125946151.png)



## When to Swap

![image-20190423130026371](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423130026371.png)

Basically, when do you make space available?

**Demand:** To swap something in, something needs to be swapped out

**Background:** lot of latency with disk, so we use a large block (like 30 pages at once) to make the use of the disk more efficient. Then there's only one mechanical operation as opposed to 30.



## Background Swapping

![image-20190423130606790](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423130606790.png)

Programs don't have to wait for evictions first. Likely won't have to wait for new memory allocations. When disk is not doing much, background swapping might occur (idle time)



## Page Faults emable lazy allocation and lazy loading

![image-20190423130828005](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423130828005.png)

When running an executable, you might just load the first few parts and page the rest of it saying they are not present.



## Page Replacement Policies

![image-20190423131259747](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423131259747.png)



## Page replacement Policy

![image-20190423131402802](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423131402802.png)

Physical page is only used to store one thing at a time

![image-20190423131601128](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423131601128.png)

It was not in cache (cold-start), required copy from disk to cache. This is an optimal policy because it has the minimal number of evictions



## Least Recently Used (LRU) approximates optimal

![image-20190423131830516](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423131830516.png)



## LRU suffers from "corner case" behaviors

![image-20190423131904074](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423131904074.png)

Results when you have repition, like looping over data that is slightly larger than cache size. This is bad because the least recently used piece of data is the one that we want to use next



## OS Performance Analysis

![image-20190423132245766](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423132245766.png)

Different sequences of operations might be better or worse depending on the policy



## Some Page Replacement Experiments (varying RAM size)

![image-20190423132317037](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423132317037.png)

HIt rate is kind of like performance

If everything is in cache, then you will hit everything (that's why top right is at 100 for all)

The 0 on the right is LRU for looping when data is larger than the cache size



## How to implement LRU

![image-20190423132958207](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423132958207.png)

basically dirty means written. 

If everything was accessed the last time that the clock algorithm checked, then it will loop around. SInce it is setting every accessed bit to 0, it will evict the first page that it started at



## Keeping your hands clean

![image-20190423133157670](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423133157670.png)

Dirty bit not being set means it was a read only page.

Throwing out pages assumes that the OS can just get back those pages from the file/from the binary.



## Thrashing

![image-20190423133621350](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423133621350.png)

If there's way to much demand from memory, it has to go to disk to get the data it needs. This would make it seem like your computer is frozen. If it seems like your computer is SUPER slow, it's probably thrashing. Everything has to come from disk.

```shell
top -n -p and something else don't remember
```



## Approximating LRU for page replacement

![image-20190423133927368](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423133927368.png)



## Disk buffering and filesystem caching

![image-20190423134138816](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423134138816.png)

Making disk look as fast as memory by just taking the contents of files and â€¦.

We use filesystem because it's bigger AND it's persistent



## `top` also reports filesystem cache size

![image-20190423134303814](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423134303814.png)

On murphy. Majority of RAM is not being used by processes, but by file system caching. This tends to be faster



## Unified Page Cache

![image-20190423134357977](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423134357977.png)

file access is bottle neck for programs so it's important to speed that up

![image-20190423134556007](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423134556007.png)



## The benefits of filesystem caching

![image-20190423135020532](/Users/gabrielrojas-westall/Library/Application Support/typora-user-images/image-20190423135020532.png)

A program could be writing to disk, using an L1 cache that is super fast. Program might be doing something really slow from the user's perspective (in the code), but if the OS has memory available, it might be fast

